{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32a049b-bb71-4bfe-852b-402285a8a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cefbde70-7cb2-4787-a5b9-473f27202ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category = 'Beauty'\n",
    "# category = 'DVDs'\n",
    "# category = 'Food & Drink'\n",
    "# category = 'Internet'\n",
    "category = 'Games'\n",
    "\n",
    "signal = 'like'\n",
    "# signal = 'write'\n",
    "# signal = 'both'\n",
    "\n",
    "# summary = 'llama'\n",
    "# summary = 'aspects'\n",
    "summary = None\n",
    "\n",
    "num_candidates = 20\n",
    "\n",
    "model = 'magnn'\n",
    "# model = 'nrms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71882ba8-a241-4b5d-a70a-5cc0cf791ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a5165d-5d42-4610-9b49-ec93da6799e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/sise/bshapira-group/lilachzi/csvs/'\n",
    "votes_file = os.path.join(data_path, 'votes_4core_split_60_20_20.tsv')\n",
    "aspects_reviews_file = os.path.join(data_path, 'ciao_4core_gpt_aspects.csv')\n",
    "summary_reviews_file = os.path.join(data_path, 'ciao_4core_summary.csv')\n",
    "full_reviews_file = os.path.join(data_path, 'ciao_4core.tsv')\n",
    "\n",
    "votes_df = pd.read_csv(votes_file, sep='\\t')\n",
    "if summary == 'llama':\n",
    "    reviews_df = pd.read_csv(summary_reviews_file)\n",
    "elif summary == 'aspects':\n",
    "    reviews_df = pd.read_csv(aspects_reviews_file)\n",
    "else:\n",
    "    reviews_df = pd.read_csv(full_reviews_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f22e857f-bef4-4665-81ce-95f274ce7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id_mapping = dict(zip(votes_df['product_id'], votes_df['product']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc5e9074-6522-4053-9d4f-f3f724b0cadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2755654/2755654 [01:53<00:00, 24322.73it/s]\n",
      "100%|██████████| 135880/135880 [00:05<00:00, 24499.31it/s]\n"
     ]
    }
   ],
   "source": [
    "positive_vote = [3, 4, 5]\n",
    "\n",
    "written_review = {}\n",
    "liked_reviews = {}\n",
    "umap = {}\n",
    "rmap = {}\n",
    "ridx2text = {}\n",
    "\n",
    "for idx, row in tqdm(votes_df.iterrows(), total=len(votes_df)):\n",
    "    review_id = row['review_id']\n",
    "    voter_id = row['voter_id']\n",
    "    vote = row['vote']\n",
    "    categ = row['category']\n",
    "    split = row['split']\n",
    "    \n",
    "    if vote in positive_vote:\n",
    "        if voter_id not in liked_reviews:\n",
    "            liked_reviews[voter_id] = {}\n",
    "        if split not in liked_reviews[voter_id]:\n",
    "            liked_reviews[voter_id][split] = []\n",
    "        liked_reviews[voter_id][split].append((review_id, categ))\n",
    "        \n",
    "    if voter_id in umap:\n",
    "        continue\n",
    "        \n",
    "    umap[voter_id] = len(umap)\n",
    "        \n",
    "for idx, row in tqdm(reviews_df.iterrows(), total=len(reviews_df)):\n",
    "    review_id = row['review_id']\n",
    "    user_id = row['user_id']\n",
    "    if summary == 'llama':\n",
    "        text = row['summary']\n",
    "    elif summary == 'aspects':\n",
    "        text = row['aspects']\n",
    "    else:\n",
    "        text = row['clean_review']\n",
    "    \n",
    "    if user_id not in written_review:\n",
    "        written_review[user_id] = []\n",
    "    written_review[user_id].append(review_id)\n",
    "    \n",
    "    if review_id in rmap:\n",
    "        continue\n",
    "\n",
    "    rmap[review_id] = len(rmap)\n",
    "    ridx2text[rmap[review_id]] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ebb88b-3e27-469d-bd98-41e7644486e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_history = 30\n",
    "write_history = 10\n",
    "\n",
    "def load_history(voter_id, rmap, written_review, liked_reviews, split, history_type, category=None):\n",
    "    history_write = [rmap[i] for i in written_review[voter_id]]\n",
    "    if split in liked_reviews.get(voter_id, []):\n",
    "        liked_reviews_user = liked_reviews[voter_id][split]\n",
    "    else:\n",
    "        liked_reviews_user = []\n",
    "    if category:\n",
    "        history_like = [rmap[liked_pair[0]] for liked_pair in liked_reviews_user if liked_pair[1] != category]\n",
    "    else:\n",
    "        history_like = [rmap[liked_pair[0]] for liked_pair in liked_reviews_user]\n",
    "\n",
    "    if history_type == 'write':\n",
    "        history = np.random.permutation(history_write)[:write_history]\n",
    "    elif history_type == 'like':\n",
    "        history = np.random.permutation(history_like)[:like_history]\n",
    "    else:  # 'both'\n",
    "        history = (list(np.random.permutation(history_write)[:write_history]) +\n",
    "                   list(np.random.permutation(history_like)[:like_history]))\n",
    "\n",
    "    history = list(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89bca3eb-3889-4dea-ace4-de91226c2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_path = '/sise/bshapira-group/lilachzi/models/llm/llama_cpp_python'\n",
    "profiles_df = pd.read_csv(os.path.join(profiles_path, f'ciao_{category}', f'{signal}_profiles.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de8b3240-7993-4afe-ae24-f86d6e841a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(os.path.join(data_path, 'train_set.csv'), converters={'y_true': eval})\n",
    "train_set = train_set[train_set['category'] == category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b222a8e-2559-4f83-b69c-0fdc09e056f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48170/48170 [00:14<00:00, 3385.14it/s]\n"
     ]
    }
   ],
   "source": [
    "train_seq = []\n",
    "train_cand = []\n",
    "\n",
    "for idx, row in tqdm(train_set.iterrows(), total=len(train_set)):\n",
    "    pid = row['product_id']\n",
    "    uidx = umap[row['voter_id']]\n",
    "    candidates = {rmap[rid]: vote for rid, vote in row['y_true'].items()}\n",
    "    answers = [rid for rid, vote in candidates.items() if vote in [3, 4, 5]]\n",
    "    # user_history = load_history(row['voter_id'], rmap, written_review, liked_reviews, 'train', signal, category)\n",
    "    user_profile = profiles_df[profiles_df['user_id'] == row['voter_id']]['profile'].item()\n",
    "    \n",
    "    for answer in answers:\n",
    "        # train_seq.append(user_history)\n",
    "        train_seq.append(user_profile)\n",
    "        negative_cands = [c for c, vote in candidates.items() if vote not in [3, 4, 5]]\n",
    "        if not negative_cands:\n",
    "            negative_cands = [c for c, vote in candidates.items() if c != answer]\n",
    "        # point-wise\n",
    "        negative_cands = random.sample(negative_cands, min(3, len(negative_cands)))\n",
    "        train_cand.append((product_id_mapping[pid], [answer] + negative_cands))\n",
    "        \n",
    "        # pair-wise\n",
    "        # negative_cand = random.choice(negative_cands)\n",
    "        # train_cand.append((product_id_mapping[pid], [answer, negative_cand]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e463029c-eb93-418b-8e93-eb488dd15ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = pd.read_csv(\n",
    "    os.path.join(output_path, f'ciao_{category.replace(\" & \", \"_\")}_{signal}', f'{model}_valid_{str(num_candidates)}_candidates.csv'),\n",
    "    converters={'candidates': eval}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83f873ff-39bc-48f4-aa7b-5ff96b03a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 83/15829 [00:00<00:06, 2586.67it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m candidates \u001b[38;5;241m=\u001b[39m {rmap[rid]: vote \u001b[38;5;28;01mfor\u001b[39;00m rid, vote \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcandidates\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# user_history = load_history(row['voter_id'], rmap, written_review, liked_reviews, 'test', signal, category)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m user_profile \u001b[38;5;241m=\u001b[39m profiles_df[profiles_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoter_id\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# val_seq.append(user_history)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m val_seq\u001b[38;5;241m.\u001b[39mappend(user_profile)\n",
      "File \u001b[0;32m/storage/modules/packages/anaconda/lib/python3.11/site-packages/pandas/core/base.py:418\u001b[0m, in \u001b[0;36mIndexOpsMixin.item\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only convert an array of size 1 to a Python scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "val_seq = []\n",
    "val_cand = []\n",
    "val_labels = []\n",
    "\n",
    "for idx, row in tqdm(valid_set.iterrows(), total=len(valid_set)):\n",
    "    pid = row['product_id']\n",
    "    uidx = umap[row['voter_id']]\n",
    "    \n",
    "    candidates = {rmap[rid]: vote for rid, vote in row['candidates'].items()}\n",
    "    # user_history = load_history(row['voter_id'], rmap, written_review, liked_reviews, 'test', signal, category)\n",
    "    user_profile = profiles_df[profiles_df['user_id'] == row['voter_id']]['profile'].item()\n",
    "    \n",
    "    # val_seq.append(user_history)\n",
    "    val_seq.append(user_profile)\n",
    "    \n",
    "    # point-wise candidates\n",
    "    val_cand.append((product_id_mapping[pid], list(candidates.keys())))\n",
    "                    \n",
    "    # pair-wise candidates\n",
    "    # val_cand.append((product_id_mapping[pid], [pair for pair in list(combinations(candidates.keys(), 2))]))\n",
    "    \n",
    "    val_labels.append(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad17adce-a080-4ce8-9ebe-2307015d84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\n",
    "    os.path.join(output_path, f'ciao_{category.replace(\" & \", \"_\")}_{signal}', f'{model}_test_{str(num_candidates)}_candidates.csv'),\n",
    "    converters={'candidates': eval}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d0e09c1-0e14-443d-ad81-f865c4d2a699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26337/26337 [00:14<00:00, 1866.78it/s]\n"
     ]
    }
   ],
   "source": [
    "test_seq = []\n",
    "test_cand = []\n",
    "test_labels = []\n",
    "\n",
    "for idx, row in tqdm(test_set.iterrows(), total=len(test_set)):\n",
    "    pid = row['product_id']\n",
    "    uidx = umap[row['voter_id']]\n",
    "    \n",
    "    candidates = {rmap[rid]: vote for rid, vote in row['candidates'].items()}\n",
    "    user_history = load_history(row['voter_id'], rmap, written_review, liked_reviews, 'test', signal, category)\n",
    "    \n",
    "    test_seq.append(user_history)\n",
    "    \n",
    "    # point-wise candidates\n",
    "    test_cand.append((product_id_mapping[pid], list(candidates.keys())))\n",
    "                    \n",
    "    # pair-wise candidates\n",
    "    # test_cand.append((product_id_mapping[pid], [pair for pair in list(combinations(candidates.keys(), 2))]))\n",
    "    \n",
    "    test_labels.append(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7703ee5-3cb9-4812-aa94-35267c6dc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train_seq': train_seq,\n",
    "    'train_cand': train_cand,\n",
    "    'val_seq': val_seq,\n",
    "    'val_cand': val_cand,\n",
    "    'val_labels': val_labels,\n",
    "    'test_seq': test_seq,\n",
    "    'test_cand': test_cand,\n",
    "    'test_labels': test_labels,\n",
    "    'meta': ridx2text,\n",
    "    'umap': umap,\n",
    "    'smap': rmap\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7c81fdd-a067-4917-9752-58be2288fdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed/ciao_Internet_both/magnn_dataset_10_pw.pkl')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = '' if not summary else f'_{summary}'\n",
    "dataset_path = Path(\n",
    "    f'/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed/ciao_{category.replace(\" & \", \"_\")}_{signal}/{model}_dataset_{str(num_candidates)}_pw{summary}.pkl'\n",
    ")\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7db4fc91-988c-4278-b0bc-1e33dead667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dataset_path.open('wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9eb10ef4-928c-411c-9818-95e99a42c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation = {\n",
    "#     'valid_labels': val_labels,\n",
    "#     'test_labels': test_labels\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10f0a040-2f1c-4b61-a697-cc9357c994ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if summary:\n",
    "#     evaluation_path = Path(\n",
    "#         f'/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed/ciao_{category.replace(\" & \", \"_\")}_{signal}_summary/evaluation.pkl'\n",
    "#     )\n",
    "# else:\n",
    "#     evaluation_path = Path(\n",
    "#         f'/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed/ciao_{category.replace(\" & \", \"_\")}_{signal}/evaluation.pkl'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "27d823d9-2581-4266-8534-f339a7ebb942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with evaluation_path.open('wb') as f:\n",
    "#     pickle.dump(evaluation, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f54d69-4453-450e-b376-465195709634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
