{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32a049b-bb71-4bfe-852b-402285a8a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cefbde70-7cb2-4787-a5b9-473f27202ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category = 'Beauty'\n",
    "# category = 'DVDs'\n",
    "# category = 'Food & Drink'\n",
    "# category = 'Internet'\n",
    "category = 'Games'\n",
    "\n",
    "# signal = 'like'\n",
    "signal = 'write'\n",
    "# signal = 'both'\n",
    "\n",
    "summary = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a5165d-5d42-4610-9b49-ec93da6799e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_file = '../csvs/votes_4core_split_60_20_20.tsv'\n",
    "aspects_reviews_file = '../csvs/ciao_4core_gpt_aspects.csv'\n",
    "summary_reviews_file = '../csvs/ciao_4core_summary.csv'\n",
    "\n",
    "votes_df = pd.read_csv(votes_file, sep='\\t')\n",
    "if summary:\n",
    "    reviews_df = pd.read_csv(summary_reviews_file)\n",
    "else:\n",
    "    reviews_df = pd.read_csv(aspects_reviews_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc5e9074-6522-4053-9d4f-f3f724b0cadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2755654/2755654 [01:52<00:00, 24438.83it/s]\n",
      "100%|██████████| 135880/135880 [00:04<00:00, 27226.35it/s]\n"
     ]
    }
   ],
   "source": [
    "positive_vote = [3, 4, 5]\n",
    "\n",
    "written_review = {}\n",
    "liked_reviews = {}\n",
    "umap = {}\n",
    "rmap = {}\n",
    "ridx2text = {}\n",
    "\n",
    "for idx, row in tqdm(votes_df.iterrows(), total=len(votes_df)):\n",
    "    review_id = row['review_id']\n",
    "    voter_id = row['voter_id']\n",
    "    vote = row['vote']\n",
    "    categ = row['category']\n",
    "    split = row['split']\n",
    "    \n",
    "    if vote in positive_vote:\n",
    "        if voter_id not in liked_reviews:\n",
    "            liked_reviews[voter_id] = {}\n",
    "        if split not in liked_reviews[voter_id]:\n",
    "            liked_reviews[voter_id][split] = []\n",
    "        liked_reviews[voter_id][split].append((review_id, categ))\n",
    "        \n",
    "    if voter_id in umap:\n",
    "        continue\n",
    "        \n",
    "    umap[voter_id] = len(umap)\n",
    "        \n",
    "for idx, row in tqdm(reviews_df.iterrows(), total=len(reviews_df)):\n",
    "    review_id = row['review_id']\n",
    "    user_id = row['user_id']\n",
    "    if summary:\n",
    "        text = row['summary']\n",
    "    else:\n",
    "        text = row['aspects']\n",
    "    \n",
    "    if user_id not in written_review:\n",
    "        written_review[user_id] = []\n",
    "    written_review[user_id].append(review_id)\n",
    "    \n",
    "    if review_id in rmap:\n",
    "        continue\n",
    "\n",
    "    rmap[review_id] = len(rmap)\n",
    "    ridx2text[rmap[review_id]] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35773db6-5a15-421d-811e-425fe98b9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # liked reviews\n",
    "# like_analysis = []\n",
    "# for u in liked_reviews:\n",
    "#     lens = []\n",
    "#     for split in ['train', 'valid', 'test']:\n",
    "#         lens.append(len(liked_reviews[u].get(split, [])))\n",
    "#     like_analysis.append(lens)\n",
    "    \n",
    "# like_analysis = pd.DataFrame(like_analysis, columns=['train', 'valid', 'test'])\n",
    "# like_analysis.describe()\n",
    "\n",
    "# written reviews\n",
    "# write_analysis = []\n",
    "# for u in written_review:\n",
    "#     write_analysis.append(len(written_review[u]))\n",
    "    \n",
    "# write_analysis = pd.DataFrame(write_analysis, columns=['train'])\n",
    "# write_analysis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73ebb88b-3e27-469d-bd98-41e7644486e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_history = 30\n",
    "write_history = 10\n",
    "\n",
    "def load_history(voter_id, rmap, written_review, liked_reviews, split, history_type, category=None):\n",
    "    history_write = [rmap[i] for i in written_review[voter_id]]\n",
    "    if split in liked_reviews.get(voter_id, []):\n",
    "        liked_reviews_user = liked_reviews[voter_id][split]\n",
    "    else:\n",
    "        liked_reviews_user = []\n",
    "    if category:\n",
    "        history_like = [rmap[liked_pair[0]] for liked_pair in liked_reviews_user if liked_pair[1] != category]\n",
    "    else:\n",
    "        history_like = [rmap[liked_pair[0]] for liked_pair in liked_reviews_user]\n",
    "\n",
    "    if history_type == 'write':\n",
    "        history = np.random.permutation(history_write)[:write_history]\n",
    "    elif history_type == 'like':\n",
    "        history = np.random.permutation(history_like)[:like_history]\n",
    "    else:  # 'both'\n",
    "        history = (list(np.random.permutation(history_write)[:write_history]) +\n",
    "                   list(np.random.permutation(history_like)[:like_history]))\n",
    "\n",
    "    history = list(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de8b3240-7993-4afe-ae24-f86d6e841a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../csvs/train_set.csv', converters={'y_true': eval})\n",
    "train_set = train_set[train_set['category'] == category]\n",
    "\n",
    "valid_set = pd.read_csv('../csvs/valid_set.csv', converters={'y_true': eval})\n",
    "valid_set = valid_set[valid_set['category'] == category]\n",
    "\n",
    "test_set = pd.read_csv('../csvs/test_set.csv', converters={'y_true': eval})\n",
    "test_set = test_set[test_set['category'] == category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b222a8e-2559-4f83-b69c-0fdc09e056f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48170/48170 [00:57<00:00, 838.16it/s] \n"
     ]
    }
   ],
   "source": [
    "train_seq = {}\n",
    "train_cand = {}\n",
    "\n",
    "for idx, row in tqdm(train_set.iterrows(), total=len(train_set)):\n",
    "    pid = row['product_id']\n",
    "    uidx = umap[row['voter_id']]\n",
    "    candidates = {rmap[rid]: vote for rid, vote in row['y_true'].items()}\n",
    "    answers = [rid for rid, vote in candidates.items() if vote in [3, 4, 5]]\n",
    "    user_history = load_history(row['voter_id'], rmap, written_review, liked_reviews, 'train', signal, category)\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        break\n",
    "    \n",
    "    if uidx not in train_seq:\n",
    "        train_seq[uidx] = []\n",
    "    if uidx not in train_cand:\n",
    "        train_cand[uidx] = []\n",
    "        \n",
    "    for answer in answers:\n",
    "        train_seq[uidx].append(user_history + [answer])\n",
    "        negative_cands = [c for c, vote in candidates.items() if vote not in [3, 4, 5]]\n",
    "        train_cand[uidx].append(negative_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f04ed363-1c95-4d9b-a03b-a5dd3797cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_seq = {}\n",
    "# val_cand = {}\n",
    "# val_labels = []\n",
    "\n",
    "# for idx, row in tqdm(valid_set.iterrows(), total=len(valid_set)):\n",
    "#     pid = row['product_id']\n",
    "#     uidx = umap[row['voter_id']]\n",
    "#     candidates = {rmap[rid]: vote for rid, vote in row['y_true'].items()}\n",
    "#     answers = [rid for rid, vote in candidates.items() if vote in [3, 4, 5]]\n",
    "#     user_history = load_history(row['voter_id'], rmap, written_review, liked_reviews, 'valid', signal, category)\n",
    "    \n",
    "#     if uidx not in val_seq:\n",
    "#         val_seq[uidx] = []\n",
    "#     if uidx not in val_cand:\n",
    "#         val_cand[uidx] = []\n",
    "        \n",
    "#     for answer in answers:\n",
    "#         val_seq[uidx].append(user_history + [answer])\n",
    "#         val_cand[uidx].append([c for c in candidates.keys()])\n",
    "#         val_labels.append(list(candidates.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83f873ff-39bc-48f4-aa7b-5ff96b03a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15829/15829 [00:07<00:00, 2233.05it/s]\n"
     ]
    }
   ],
   "source": [
    "val_seq = {}\n",
    "val_cand = {}\n",
    "val_labels = {}\n",
    "\n",
    "for idx, row in tqdm(valid_set.iterrows(), total=len(valid_set)):\n",
    "    pid = row['product_id']\n",
    "    uidx = umap[row['voter_id']]\n",
    "    \n",
    "    candidates = {rmap[rid]: vote for rid, vote in row['y_true'].items()}\n",
    "    \n",
    "    # candidates_to_shuffle = list(candidates.items())\n",
    "    # random.shuffle(candidates_to_shuffle)\n",
    "    # candidates = dict(candidates_to_shuffle)\n",
    "    \n",
    "    user_history = load_history(row['voter_id'], rmap, written_review, liked_reviews, 'test', signal, category)\n",
    "    \n",
    "    if uidx not in val_seq:\n",
    "        val_seq[uidx] = []\n",
    "    if uidx not in val_cand:\n",
    "        val_cand[uidx] = []\n",
    "    if uidx not in val_labels:\n",
    "        val_labels[uidx] = []\n",
    "        \n",
    "    max_value = max(candidates.values())\n",
    "    answer = random.choice([rid for rid, vote in candidates.items() if vote == max_value])\n",
    "    \n",
    "    val_seq[uidx].append(user_history + [answer])\n",
    "    val_cand[uidx].append([c for c in candidates.keys()])\n",
    "    # val_labels.append(sorted(list(candidates.values()), reverse=True))\n",
    "    val_labels[uidx].append(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e4cb02e-485a-4c07-902f-c65769378ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_seq = {}\n",
    "# test_cand = {}\n",
    "# test_labels = []\n",
    "\n",
    "# for idx, row in tqdm(test_set.iterrows(), total=len(test_set)):\n",
    "#     pid = row['product_id']\n",
    "#     uidx = umap[row['voter_id']]\n",
    "#     candidates = {rmap[rid]: vote for rid, vote in row['y_true'].items()}\n",
    "#     answers = [rid for rid, vote in candidates.items() if vote in [3, 4, 5]]\n",
    "#     user_history = load_history(row['voter_id'], rmap, written_review, liked_reviews, 'test', signal, category)\n",
    "    \n",
    "#     if uidx not in test_seq:\n",
    "#         test_seq[uidx] = []\n",
    "#     if uidx not in test_cand:\n",
    "#         test_cand[uidx] = []\n",
    "        \n",
    "#     for answer in answers:\n",
    "#         test_seq[uidx].append(user_history + [answer])\n",
    "#         test_cand[uidx].append([c for c in candidates.keys()])\n",
    "#         test_labels.append(list(candidates.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d0e09c1-0e14-443d-ad81-f865c4d2a699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15792/15792 [00:07<00:00, 2228.50it/s]\n"
     ]
    }
   ],
   "source": [
    "test_seq = {}\n",
    "test_cand = {}\n",
    "test_labels = {}\n",
    "\n",
    "for idx, row in tqdm(test_set.iterrows(), total=len(test_set)):\n",
    "    pid = row['product_id']\n",
    "    uidx = umap[row['voter_id']]\n",
    "    candidates = {rmap[rid]: vote for rid, vote in row['y_true'].items()}\n",
    "    user_history = load_history(row['voter_id'], rmap, written_review, liked_reviews, 'test', signal, category)\n",
    "    \n",
    "    if uidx not in test_seq:\n",
    "        test_seq[uidx] = []\n",
    "    if uidx not in test_cand:\n",
    "        test_cand[uidx] = []\n",
    "    if uidx not in test_labels:\n",
    "        test_labels[uidx] = []\n",
    "        \n",
    "    max_value = max(candidates.values())\n",
    "    answer = random.choice([rid for rid, vote in candidates.items() if vote == max_value])\n",
    "    \n",
    "    test_seq[uidx].append(user_history + [answer])\n",
    "    test_cand[uidx].append([c for c in candidates.keys()])\n",
    "    test_labels[uidx].append(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7703ee5-3cb9-4812-aa94-35267c6dc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train_seq': train_seq,\n",
    "    'train_cand': train_cand,\n",
    "    'val_seq': val_seq,\n",
    "    'val_cand': val_cand,\n",
    "    'val_labels': val_labels,\n",
    "    'test_seq': test_seq,\n",
    "    'test_cand': test_cand,\n",
    "    'test_labels': test_labels,\n",
    "    'meta': ridx2text,\n",
    "    'umap': umap,\n",
    "    'smap': rmap\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7c81fdd-a067-4917-9752-58be2288fdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed/ciao_Games_write/dataset.pkl')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if summary:\n",
    "    dataset_path = Path(\n",
    "        f'/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed/ciao_{category.replace(\" & \", \"_\")}_{signal}_summary/dataset.pkl'\n",
    "    )\n",
    "else:\n",
    "    dataset_path = Path(\n",
    "        f'/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed/ciao_{category.replace(\" & \", \"_\")}_{signal}/dataset.pkl'\n",
    "    )\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7db4fc91-988c-4278-b0bc-1e33dead667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dataset_path.open('wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9eb10ef4-928c-411c-9818-95e99a42c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation = {\n",
    "#     'valid_labels': val_labels,\n",
    "#     'test_labels': test_labels\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10f0a040-2f1c-4b61-a697-cc9357c994ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if summary:\n",
    "#     evaluation_path = Path(\n",
    "#         f'/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed/ciao_{category.replace(\" & \", \"_\")}_{signal}_summary/evaluation.pkl'\n",
    "#     )\n",
    "# else:\n",
    "#     evaluation_path = Path(\n",
    "#         f'/sise/bshapira-group/lilachzi/models/LlamaRec/data/preprocessed/ciao_{category.replace(\" & \", \"_\")}_{signal}/evaluation.pkl'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "27d823d9-2581-4266-8534-f339a7ebb942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with evaluation_path.open('wb') as f:\n",
    "#     pickle.dump(evaluation, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f54d69-4453-450e-b376-465195709634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2ffe3760-fd6e-47b2-a708-a89bd44507f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seqs = []\n",
    "all_cands = []\n",
    "all_labels = []\n",
    "for u in val_seq.keys():\n",
    "    for seq, cand, labels in zip(val_seq[u], val_cand[u], val_labels[u]):\n",
    "        answer = seq[-1]\n",
    "        np.random.shuffle(cand)\n",
    "        all_labels.append([labels[i] for i in cand])\n",
    "        \n",
    "        if len(cand) <= 19 + 1:\n",
    "            # self.rng.shuffle(cand)\n",
    "            all_seqs += [seq]\n",
    "            all_cands += [cand]\n",
    "        else:\n",
    "            cand.pop(cand.index(answer))\n",
    "            for i in range(0, len(cand), 19):\n",
    "                all_seqs += [seq]\n",
    "                batch = cand[i:i+19] + [answer]\n",
    "                # self.rng.shuffle(batch)\n",
    "                all_cands += [batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "db7f4625-d747-4261-b2ac-a5f1b5f852eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22919, 22919, 15829)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_seqs), len(all_cands), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "424320ef-2daa-4f57-8094-c2f1017bc0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "batch_size = 20\n",
    "for labels in all_labels:\n",
    "    # labels = torch.tensor(labels)\n",
    "    batches = len([i for i in range(0, len(labels) - 1, batch_size - 1)])\n",
    "    # scores = model_scores[i:i+batches]\n",
    "    # if len(scores) > 1:\n",
    "    #     scores = scores / torch.sum(scores, dim=1, keepdim=True)\n",
    "    # answers = model_labels[i:i+batches]\n",
    "    i += batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "710368e0-2173-4a67-a0e6-2b4ceda52fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22919"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2636bda6-c796-4e21-8c62-24b432feee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_negative_sample_size = 19\n",
    "window_size = 10 \n",
    "step = 3\n",
    "\n",
    "all_seqs = []\n",
    "all_cands = []\n",
    "all_labels = []\n",
    "for u in val_seq.keys():\n",
    "    for seq, cand, labels in zip(val_seq[u], val_cand[u], val_labels[u]):\n",
    "        np.random.shuffle(cand)\n",
    "        all_labels.append([labels[i] for i in cand])\n",
    "\n",
    "        if len(cand) <= llm_negative_sample_size + 1:\n",
    "            all_seqs += [seq]\n",
    "            all_cands += [cand]\n",
    "        else:\n",
    "            for i in range(0, len(cand)- window_size + 1, step):\n",
    "                all_seqs += [seq]\n",
    "                all_cands += [cand[i:i+window_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c81a3fed-6ddc-4c37-b87e-9eea5f4f43db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59515, 59515, 15829)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_seqs), len(all_cands), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a2bb800-2b8e-473f-b2c5-fa473e250c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for labels in all_labels[:100]:\n",
    "    if len(labels) <= llm_negative_sample_size + 1:\n",
    "        i += 1\n",
    "    else:\n",
    "        num_windows = len(range(0, len(labels) - window_size + 1, step))\n",
    "        i += num_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d93173a3-3d53-4acf-a8e3-e204badcd499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17ca00-e93f-4e27-8e6d-9a959fa4aec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
